---
format:
  revealjs:
    logo: "https://cms-cdn.lmu.de/assets/img/Logo_LMU.svg"
    footer: "[Advanced Text Analysis - SICSS-Munich 2023 - Valerie Hase](https://github.com/valeriehase)"
    center-title-slide: false
    theme: ["theme/q-theme.scss"]
    highlight-style: atom-one
    code-fold: show
    code-copy: true
    self-contained: true
    number-sections: false
    smaller: true
    progress: true
execute:
  echo: true
bibliography: "references/references.bib"
csl: references/apa.csl
editor: 
  markdown: 
    wrap: 72
---

<h1>Advanced Text Analysis</h1>

<h2>SICSS-Munich, Day 4</h2>

<hr>

Session 3Ô∏è‚É£: Vector Space Models

Valerie Hase (LMU Munich)

`r fontawesome::fa("github", "black")`
[github.com/valeriehase](https://github.com/valeriehase)

`r fontawesome::fa("globe", "black")`
[valerie-hase.com](https://valerie-hase.com/)

## Agenda

-   (Sparse) Vector Space Models (VSM)
-   Their Limitations

## Going beyond bag-of-words

-   Identifying meaning through ngrams (Session 2Ô∏è‚É£)
-   Identifying meaning through syntax (Session 2Ô∏è‚É£)
-   __Identifying meaning through semantic spaces__ (Session 3Ô∏è‚É£, 4Ô∏è‚É£)


## Vector Space Models

-   [Vector Space
    Models](https://en.wikipedia.org/wiki/Vector_space_model){target="_blank"} (VSM):
    Represent documents/words as a vector in a vector space: Vectors
    that are closer together in space are semantically similar and
    vectors that are far apart are semantically distant.
    [@turney_frequency_2010]
-   Idea very much pre-CSS

-   Stems from information retrieval [@salton_smart_1971]
-   We start with: **documents as vectors**

## Documents as Vectors

Basic idea (& some notation ü§ì)

::: incremental
-   Let $w$ be a word

-   Let $D = (w_1, w_2, w_3, ‚Ä¶, w_N)$ be a document consisting of
    sequences of words. For example, $D_1$: *"I like fruit like apple
    and kiwi"*.

-   Let $V$ be the vocabulary, with size
    $|V|$ = $N$ (number of unique words)
:::

## Documents as Vectors

- Idea üí°: We can represent each document $D$ via a frequency vector including all its words:

- Take example sentence $D_1$: *"I like fruit like apple and kiwi"*

::: incremental
-   $D_1$ = (I, like, fruit, like, apple, and, kiwi)

-   $V$ = (I, like, fruit, apple, and, kiwi), $|V|$ = 6
:::

## Documents as Vectors

- Idea üí°: We can represent each document $D$ via a frequency vector described by its words which is located in an $N$-dimensional space:

- Take example sentence $D_1$: *"I like fruit like apple and kiwi"*

- Document represented as seven vectors $D_1 = (w_1, w_2, w_3, ‚Ä¶, w_7)$, one for each $w_i$, of length $|V|$ = $N$ = 6 (our dimensions) including only 0/1 (*one-hot-encoding*):

$$V_{D_1} = \sum_{i=1}^{7} V_{wi} =\begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix} + \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 1 
\\ 0 \\  0 \\ 0 \\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 0 \\ 1 \\ 0\\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 1\\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 1\end{pmatrix} = \begin{pmatrix} 1 \\ 2 \\ 1 \\ 1 \\ 1\\ 1\end{pmatrix}$$

## Documents as Vectors

- Idea üí°: We can represent each document $D$ via a frequency vector described by its words which is located in an $N$-dimensional space:

- Take example sentence $D_1$: *"I like fruit like apple and kiwi"*

- Document represented as seven vectors $D_1 = (w_1, w_2, w_3, ‚Ä¶, w_7)$, one for each $w_i$, of length $|V|$ = $N$ = 6 (our dimensions) including only 0/1 (*one-hot-encoding*):

- Document then represend via a single word-frequency vector [1, 2, 1, 1, 1, 1]

## Documents as Vectors

-   Using the vector representation, we can now represent the sentence *"I like fruit like apple and kiwi"* in a $N$-dimensional vector space.

-   To create a 2-dimensional vector space, we only consider words *"kiwi"* as the $x$-axis and and
    *"like"* as the $y$-axis:

```{r, echo = FALSE}
#Ignore this output, if needed - merely a way of creating this figure
#data
data <- data.frame(x_0 = c(0),
                   y_0 = c(0),
                   x_1 = c(1),
                   y_1 = c(2))

#plot
library("ggplot2")
library("dplyr")
library("quanteda")
ggplot(data)+
  geom_hline(yintercept = 0) + 
  geom_vline(xintercept = 0) +
  ylim(0, 3) + xlim(0, 3)+
  geom_segment(aes(x = x_0, y = y_0, xend = x_1, yend = y_1), arrow = arrow(length = unit(.8,"cm"),angle = 20), color = "#00893B", lwd = .8, lineend = "square", linejoin = "bevel") +
  xlab("Frequency of feature kiwi") +
  ylab("Frequency of feature like") + 
  theme_minimal() +
  annotate("text", label = "I like fruit like apple and kiwi", x = 1.2, y = 2.2, size = 6, colour = "#00893B")
```

## Documents as Vectors

-   Now, we let's add two other sentences to see how they compare: *"I like kiwi, only kiwi"* (Sentence 2) and *"I only like vegetables, especially potato"* (Sentence 3).
    ```{r, echo = FALSE}
    #Ignore this output, if needed - merely a way of creating this figure
    #data
    data <- data.frame(x_0 = c(0, 0, 0),
                       y_0 = c(0, 0, 0),
                       x_1 = c(1, 2, 0),
                       y_1 = c(2, 1, 1))

    #plot
    ggplot(data)+
      geom_hline(yintercept = 0) + 
      geom_vline(xintercept = 0) +
      ylim(0, 3) + xlim(0, 3)+
      geom_segment(aes(x = x_0, y = y_0, xend = x_1, yend = y_1), arrow = arrow(length = unit(.8,"cm"), angle = 20), color = rep("#00893B", 3), lwd = .8, lineend = "square", linejoin = "bevel") +
      ylab("Frequency of feature like") + 
      xlab("Frequency of feature kiwi") + 
      theme_minimal() +
      annotate("text", label = "I like fruit like apple and kiwi", x = 1.1, y = 2.1, size = 4, colour = "#00893B") +
      annotate("text", label = "I like kiwi, only kiwi", x = 2, y = 0.6, size = 4, colour = "#00893B") +
      annotate("text", label = "I only\nlike vegetables,\nespecially potato", x = 0.25, y = 1.2, size = 4, colour = "#00893B")
    ```

## Documents as Vectors

-   We can now calculate the distance between these vectors
-   Use distance/similarity metrics (e.g., Euclidean distance, cosine similarity, etc).

```{r, echo = FALSE}
#Ignore this output, if needed - merely a way of creating this figure
#plot
ggplot(data)+
  geom_hline(yintercept = 0) + 
  geom_vline(xintercept = 0) +
  ylim(0, 3) + xlim(0, 3)+
  geom_segment(aes(x = x_0, y = y_0, xend = x_1, yend = y_1), arrow = arrow(length = unit(.8,"cm"), angle = 20), color = rep("#00893B", 3), lwd = .8, lineend = "square", linejoin = "bevel") +
  ylab("Frequency of feature like") + 
  xlab("Frequency of feature kiwi") + 
  theme_minimal() +
      annotate("text", label = "I like fruit like apple and kiwi", x = 1.1, y = 2.1, size = 4, colour = "#00893B") +
      annotate("text", label = "I like kiwi, only kiwi", x = 2, y = 0.6, size = 4, colour = "#00893B") +
      annotate("text", label = "I only\nlike vegetables,\nespecially potato", x = 0.25, y = 1.2, size = 4, colour = "#00893B") +
  geom_segment(aes(x = 1.5, y = 1.5, xend = 1, yend = 1.3), arrow = arrow(length = unit(.4,"cm"), angle = 20), color = "black", lwd = .8,
               lineend = "square", linejoin = "bevel") +
  annotate("text", label = "Calculate distance", x = 1.6, y = 1.6, size = 4, colour = "black")
```

## Documents as Vectors in R `r fontawesome::fa("hand", "black")`

-   In R, we can compute similarities between word vectors:
    - set-up vectors (e.g., sentence 1 as [1, 2] in 2-dimensional space)
    - compute similarity/distance, e.g. using `cosine` function from `lsa`
-   However, packages like `textreuse` make this bit easier (and offer more/better methods)

```{r}
library("lsa")
sent_1 <- c(1, 2)
sent_2 <- c(2, 1)
sent_3 <- c(0, 1)
cosine(sent_1, sent_3)
cosine(sent_1, sent_2)
```

##

::: {style="font-size: 200%;text-align:center;"}
**How could we use these methods for social science questions?** ü§î
:::

## Identifying meaning through semantic spaces (sparse VSM): Overview üìö

-   **Methods**: Documents as sparse vectors (for now) in $N$-dimensional space

-   **Use for**: Text similarity, text-reuse, plagiarism detection, media bias

-   **Examplary studies**:

    -   for measuring media bias: @mozer_matching_2020

-   **Packages**: 
    - [lsa](https://cran.r-project.org/web/packages/textreuse)
    - [textreuse](https://cran.r-project.org/web/packages/textreuse) and
    related publication [@mullen_2020]


## Word as Vectors

We already know that we can also represent word as vectors! 

Remember the *one-hot-encoding* of the sentence _I like fruit like apple and kiwi_?

$$V_{D_1} = \sum_{i=1}^{7} V_{wi} =\begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix} + \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 1 
\\ 0 \\  0 \\ 0 \\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 0 \\ 1 \\ 0\\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 1\\ 0\end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 1\end{pmatrix} = \begin{pmatrix} 1 \\ 2 \\ 1 \\ 1 \\ 1\\ 1\end{pmatrix}$$

## Wait... is this not still bag-of-words?

Yes! üëÄ - so old & new problems of (sparse) VSM include...

- ‚ùå Computationally inefficient (large , sparse vectors!)

- ‚ùå Semantic meaning of words not captured: similar words, different
vectors

‚è≠Ô∏è Welcome to the world of distributed representations, especially: embeddings! (next up!)

##

::: {style="font-size: 400%;text-align:center;"}
**Any questions?** ü§î
:::

## References
